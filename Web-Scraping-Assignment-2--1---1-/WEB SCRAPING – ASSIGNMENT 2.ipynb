{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f0f8675",
   "metadata": {},
   "source": [
    "# WEB SCRAPING ‚Äì ASSIGNMENT 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d2cb4c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\patil\\anaconda3\\lib\\site-packages (4.17.2)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\patil\\anaconda3\\lib\\site-packages (from selenium) (0.24.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\patil\\anaconda3\\lib\\site-packages (from selenium) (2022.12.7)\n",
      "Requirement already satisfied: urllib3[socks]<3,>=1.26 in c:\\users\\patil\\anaconda3\\lib\\site-packages (from selenium) (1.26.14)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\patil\\anaconda3\\lib\\site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: typing_extensions>=4.9.0 in c:\\users\\patil\\anaconda3\\lib\\site-packages (from selenium) (4.9.0)\n",
      "Requirement already satisfied: attrs>=20.1.0 in c:\\users\\patil\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (22.1.0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in c:\\users\\patil\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0)\n",
      "Requirement already satisfied: idna in c:\\users\\patil\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.4)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\patil\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: exceptiongroup in c:\\users\\patil\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\patil\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.1)\n",
      "Requirement already satisfied: outcome in c:\\users\\patil\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\patil\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\patil\\anaconda3\\lib\\site-packages (from urllib3[socks]<3,>=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\patil\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\patil\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "146a58bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "import warnings \n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097248d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "01bb2938",
   "metadata": {},
   "source": [
    "**Q1: Write a python program to scrape data for ‚ÄúData Analyst‚Äù Job position in ‚ÄúBangalore‚Äù location. You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:**\n",
    "\n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter ‚ÄúData Analyst‚Äù in ‚ÄúJob title, Skills‚Äù field and enter ‚ÄúBangalore‚Äù in ‚Äúenter the location‚Äù field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "a3093a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "46c7ebb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.shine.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "d40bb638",
   "metadata": {},
   "outputs": [],
   "source": [
    "designation = driver.find_element(By.CLASS_NAME, 'form-control')\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2c4babff",
   "metadata": {},
   "outputs": [],
   "source": [
    "location = driver.find_element(By.XPATH,'/html/body/div/div[1]/div/div/div[1]/div[1]/div/div[2]/div/div[1]/form/div/div[1]/ul/li[2]/div/input')\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9795fb6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.CLASS_NAME,'searchForm_btnWrap_advance__VYBHN')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "d817c557",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "job_location =[]\n",
    "company_name =[]\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5452761f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lead Data Analyst</td>\n",
       "      <td></td>\n",
       "      <td>ara resources private limited</td>\n",
       "      <td>4 to 9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>+3</td>\n",
       "      <td>diraa hr services hiring for mncs</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Vacancy For Data Analyst</td>\n",
       "      <td>+14</td>\n",
       "      <td>yogita staffing solution</td>\n",
       "      <td>0 to 3 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Modeler data</td>\n",
       "      <td></td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Modeller</td>\n",
       "      <td></td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Modeler Bangalore</td>\n",
       "      <td></td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Modeler</td>\n",
       "      <td></td>\n",
       "      <td>boyen haddin consulting and technol...</td>\n",
       "      <td>3 to 6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>+4</td>\n",
       "      <td>quiscon biotech</td>\n",
       "      <td>0 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analyst Hiring Fresher and Experience</td>\n",
       "      <td>+13</td>\n",
       "      <td>kavya interprises</td>\n",
       "      <td>0 to 4 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    job_title job_location  \\\n",
       "0                           Lead Data Analyst                \n",
       "1                                Data Analyst           +3   \n",
       "2                    Vacancy For Data Analyst          +14   \n",
       "3                       Clinical Data Analyst           +6   \n",
       "4                           Data Modeler data                \n",
       "5                               Data Modeller                \n",
       "6                      Data Modeler Bangalore                \n",
       "7                                Data Modeler                \n",
       "8                       Clinical Data Analyst           +4   \n",
       "9  Data Analyst Hiring Fresher and Experience          +13   \n",
       "\n",
       "                             company_name experience_required  \n",
       "0           ara resources private limited          4 to 9 Yrs  \n",
       "1       diraa hr services hiring for mncs           0 to 1 Yr  \n",
       "2                yogita staffing solution          0 to 3 Yrs  \n",
       "3                           techno endura           0 to 1 Yr  \n",
       "4  boyen haddin consulting and technol...          3 to 6 Yrs  \n",
       "5  boyen haddin consulting and technol...          3 to 6 Yrs  \n",
       "6  boyen haddin consulting and technol...          3 to 6 Yrs  \n",
       "7  boyen haddin consulting and technol...          3 to 6 Yrs  \n",
       "8                         quiscon biotech          0 to 2 Yrs  \n",
       "9                       kavya interprises          0 to 4 Yrs  "
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = driver.find_elements(By.XPATH,'//h2[@itemprop= \"name\"]')\n",
    "for i in title:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "location = driver.find_elements(By.XPATH, '//div[@class = \" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for l in location:\n",
    "    location = l.text\n",
    "    job_location.append(location)\n",
    "\n",
    "comp_name = driver.find_elements(By.XPATH,'//div[@class = \"jobCard_jobCard_cName__mYnow\"]/span')\n",
    "for c in comp_name:\n",
    "    comp_name = c.text\n",
    "    company_name.append(comp_name)\n",
    "\n",
    "exp = driver.find_elements(By.XPATH, '//div[@class = \" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for e in exp:\n",
    "    exp = e.text\n",
    "    experience_required.append(exp)\n",
    "\n",
    "data = {'job_title':job_title[:10], \n",
    "       'job_location':job_location[:10],\n",
    "        'company_name':company_name[:10],\n",
    "        'experience_required':experience_required[:10]\n",
    "       }\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c044e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d4db776",
   "metadata": {},
   "source": [
    "**Q2: Write a python program to scrape data for ‚ÄúData Scientist‚Äù Job position in ‚ÄúBangalore‚Äù location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:**\n",
    "    \n",
    "1. First get the webpage https://www.shine.com/\n",
    "2. Enter ‚ÄúData Scientist‚Äù in ‚ÄúJob title, Skills‚Äù field and enter ‚ÄúBangalore‚Äù in ‚Äúenter the location‚Äù field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "a79e200f",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.shine.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "bb8db934",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = driver.find_element(By.XPATH, '/html/body/div/div[1]/div/div/div[1]/div[1]/div/div[2]/div/div[1]/form/div/div[1]/ul/li[1]/div/input')\n",
    "job.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "013f4d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "place = driver.find_element(By.XPATH,'/html/body/div/div[1]/div/div/div[1]/div[1]/div/div[2]/div/div[1]/form/div/div[1]/ul/li[2]/div/input')\n",
    "place.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "5b34ea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,'/html/body/div/div[1]/div/div/div[1]/div[1]/div/div[2]/div/div[1]/form/div/div[2]/div/button')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e4e82a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "job_location =[]\n",
    "company_name =[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "cce746b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist Recruitment</td>\n",
       "      <td>Bangalore\\n+15</td>\n",
       "      <td>renuka interprises</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Scientist Recruitment</td>\n",
       "      <td>Bangalore\\n+15</td>\n",
       "      <td>renuka interprises</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore\\n+4</td>\n",
       "      <td>acme services private limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>ltimindtree limited</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Lead Data Scientist/ Principal Data Scientist</td>\n",
       "      <td>Bangalore\\n+1</td>\n",
       "      <td>fractal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore\\n+1</td>\n",
       "      <td>neostats</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Vacancy For Data Scientist Fresher and Experience</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>yogita staffing solution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Lead Data Scientist</td>\n",
       "      <td>Bangalore\\n+1</td>\n",
       "      <td>aereo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore\\n+7</td>\n",
       "      <td>people staffing solutions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Scientist Urgent Vacancy</td>\n",
       "      <td>Bangalore\\n+14</td>\n",
       "      <td>yogita staffing solution</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           job_title    job_location  \\\n",
       "0                         Data Scientist Recruitment  Bangalore\\n+15   \n",
       "1                         Data Scientist Recruitment  Bangalore\\n+15   \n",
       "2                                     Data Scientist   Bangalore\\n+4   \n",
       "3                                     Data Scientist       Bangalore   \n",
       "4      Lead Data Scientist/ Principal Data Scientist   Bangalore\\n+1   \n",
       "5                              Senior Data Scientist   Bangalore\\n+1   \n",
       "6  Vacancy For Data Scientist Fresher and Experience  Bangalore\\n+14   \n",
       "7                                Lead Data Scientist   Bangalore\\n+1   \n",
       "8                                     Data Scientist   Bangalore\\n+7   \n",
       "9                      Data Scientist Urgent Vacancy  Bangalore\\n+14   \n",
       "\n",
       "                    company_name  \n",
       "0             renuka interprises  \n",
       "1             renuka interprises  \n",
       "2  acme services private limited  \n",
       "3            ltimindtree limited  \n",
       "4                        fractal  \n",
       "5                       neostats  \n",
       "6       yogita staffing solution  \n",
       "7                          aereo  \n",
       "8      people staffing solutions  \n",
       "9       yogita staffing solution  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = driver.find_elements(By.XPATH,'//h2[@itemprop=\"name\"]/a')\n",
    "for t in title:\n",
    "    title = t.text\n",
    "    job_title.append(title)\n",
    "\n",
    "job_loc = driver.find_elements(By.XPATH, '//div[@class = \" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for j in job_loc:\n",
    "    job_loc = j.text\n",
    "    job_location.append(job_loc)\n",
    "\n",
    "com_name = driver.find_elements(By.XPATH,'//div[@class = \"jobCard_jobCard_cName__mYnow\"]/span')\n",
    "for c in com_name:\n",
    "    com_name =c.text\n",
    "    company_name.append(com_name)\n",
    "\n",
    "dat = {'job_title': job_title[:10],\n",
    "      'job_location': job_location[:10],\n",
    "      'company_name': company_name[:10]}\n",
    "\n",
    "df = pd.DataFrame(dat)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a038fd",
   "metadata": {},
   "source": [
    "**Q3: In this question you have to scrape data using the filters available on the webpage\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for ‚ÄúData Scientist‚Äù designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required. The location filter to be used is ‚ÄúDelhi/NCR‚Äù. The salary filter to be used is ‚Äú3-6‚Äù lakhs\n",
    "The task will be done as shown in the below steps:**\n",
    "1. first get the web page https://www.shine.com/\n",
    "2. Enter ‚ÄúData Scientist‚Äù in ‚ÄúSkill, Designations, and Companies‚Äù field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "c077272b",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "8a64e1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.shine.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "328c92a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = driver.find_element(By.XPATH, '/html/body/div/div[1]/div/div/div[1]/div[1]/div/div[2]/div/div/form/div/div[1]/ul/li[1]/div/input')\n",
    "job.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "0be5d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "search = driver.find_element(By.XPATH,'/html/body/div/div[1]/div/div/div[1]/div[1]/div/div[2]/div/div[1]/form/div/div[2]/div/button')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "68b7cb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loc = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[3]/div/div/div/div[2]/div/ul/li[1]/button')\n",
    "loc.click()\n",
    "location_filter = driver.find_element(By.XPATH,'/html/body/div[3]/div/div/div/div[3]/div/div/div/ul/li[13]/span/label')\n",
    "location_filter.click()\n",
    "search = driver.find_element(By.XPATH,'/html/body/div[3]/div/div/div/div[4]/button[2]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "fcf4dc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "sal = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[3]/div/div/div/div[2]/div/ul/li[3]/button')\n",
    "sal.click()\n",
    "salary_filter = driver.find_element(By.XPATH, '/html/body/div[3]/div/div/div/div[3]/div/div/div/ul/li[3]/span/label')\n",
    "salary_filter.click()\n",
    "search = driver.find_element(By.XPATH,'/html/body/div[3]/div/div/div/div[4]/button[2]')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "e831a66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "job_location =[]\n",
    "company_name =[]\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "744cd326",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_title</th>\n",
       "      <th>job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi\\n+4</td>\n",
       "      <td>acme services private limited</td>\n",
       "      <td>3 to 5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Clinical Data Analyst</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bioanalytical Research</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bioanalytical Research Associates</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Clinical Data Management</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Clinical Analyst Fresher</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Clinical SAS</td>\n",
       "      <td>Delhi\\n+8</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 2 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Junior Clinical Data Management</td>\n",
       "      <td>Delhi\\n+6</td>\n",
       "      <td>techno endura</td>\n",
       "      <td>0 to 1 Yr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Delhi\\n+9</td>\n",
       "      <td>future solution centre</td>\n",
       "      <td>10 to 20 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Biostatistician</td>\n",
       "      <td>Delhi\\n+17</td>\n",
       "      <td>national seeds corporation limited</td>\n",
       "      <td>2 to 7 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           job_title job_location  \\\n",
       "0                     Data Scientist    Delhi\\n+4   \n",
       "1              Clinical Data Analyst    Delhi\\n+6   \n",
       "2             Bioanalytical Research    Delhi\\n+6   \n",
       "3  Bioanalytical Research Associates    Delhi\\n+6   \n",
       "4           Clinical Data Management    Delhi\\n+6   \n",
       "5           Clinical Analyst Fresher    Delhi\\n+6   \n",
       "6                       Clinical SAS    Delhi\\n+8   \n",
       "7    Junior Clinical Data Management    Delhi\\n+6   \n",
       "8                      Data Engineer    Delhi\\n+9   \n",
       "9                    Biostatistician   Delhi\\n+17   \n",
       "\n",
       "                         company_name experience_required  \n",
       "0       acme services private limited          3 to 5 Yrs  \n",
       "1                       techno endura           0 to 1 Yr  \n",
       "2                       techno endura           0 to 1 Yr  \n",
       "3                       techno endura           0 to 1 Yr  \n",
       "4                       techno endura           0 to 1 Yr  \n",
       "5                       techno endura           0 to 1 Yr  \n",
       "6                       techno endura          0 to 2 Yrs  \n",
       "7                       techno endura           0 to 1 Yr  \n",
       "8              future solution centre        10 to 20 Yrs  \n",
       "9  national seeds corporation limited          2 to 7 Yrs  "
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title = driver.find_elements(By.XPATH,'//h2[@itemprop= \"name\"]')\n",
    "for i in title:\n",
    "    title = i.text\n",
    "    job_title.append(title)\n",
    "\n",
    "location = driver.find_elements(By.XPATH, '//div[@class = \" jobCard_jobCard_lists_item__YxRkV jobCard_locationIcon__zrWt2\"]')\n",
    "for l in location:\n",
    "    location = l.text\n",
    "    job_location.append(location)\n",
    "\n",
    "comp_name = driver.find_elements(By.XPATH,'//div[@class = \"jobCard_jobCard_cName__mYnow\"]/span')\n",
    "for c in comp_name:\n",
    "    comp_name = c.text\n",
    "    company_name.append(comp_name)\n",
    "\n",
    "exp = driver.find_elements(By.XPATH, '//div[@class = \" jobCard_jobCard_lists_item__YxRkV jobCard_jobIcon__3FB1t\"]')\n",
    "for e in exp:\n",
    "    exp = e.text\n",
    "    experience_required.append(exp)\n",
    "\n",
    "data = {'job_title':job_title[:10], \n",
    "       'job_location':job_location[:10],\n",
    "        'company_name':company_name[:10],\n",
    "        'experience_required':experience_required[:10]\n",
    "       }\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5696d2b8",
   "metadata": {},
   "source": [
    "**Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "6. Brand\n",
    "7. Product Description\n",
    "8. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "To scrape the data you have to go through following steps:**\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter ‚Äúsunglasses‚Äù in the search field where ‚Äúsearch for products, brands and more‚Äù is written and click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the required data as usual.\n",
    "4. After scraping data from the first page, go to the ‚ÄúNext‚Äù Button at the bottom other page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100sunglasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "02d3bb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "71adecf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "96c5eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "search_box = driver.find_element(By.XPATH, \"//input[@title='Search for products, brands and more']\")\n",
    "search_box.send_keys('sunglasses')\n",
    "search_box.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "ded2dc35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#find = driver.find_element(By.XPATH,'/html/body/div/div/div[1]/div[1]/div[2]/div[2]/form/div/button/svg')\n",
    "#find.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "9391059d",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = []\n",
    "prod_desc = []\n",
    "price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "bd9aeab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product_Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>VOYAGE</td>\n",
       "      <td>Polarized, UV Protection Sports Sunglasses (55)</td>\n",
       "      <td>‚Çπ1,429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Lenskart STUDIO</td>\n",
       "      <td>Polarized, UV Protection Aviator Sunglasses (51)</td>\n",
       "      <td>‚Çπ1,429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRPM</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>‚Çπ149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Elligator</td>\n",
       "      <td>UV Protection Retro Square Sunglasses (54)</td>\n",
       "      <td>‚Çπ149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>VINCENT CHASE</td>\n",
       "      <td>by Lenskart Polarized, UV Protection Wayfarer ...</td>\n",
       "      <td>‚Çπ499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>ROADWAY</td>\n",
       "      <td>UV Protection Rectangular Sunglasses (Free Size)</td>\n",
       "      <td>‚Çπ179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>GANSTA</td>\n",
       "      <td>UV Protection Wayfarer, Over-sized Sunglasses ...</td>\n",
       "      <td>‚Çπ292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Eyewearlabs</td>\n",
       "      <td>UV Protection Butterfly Sunglasses (60)</td>\n",
       "      <td>‚Çπ1,236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Bembika</td>\n",
       "      <td>UV Protection Wayfarer Sunglasses (50)</td>\n",
       "      <td>‚Çπ189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>PIRASO</td>\n",
       "      <td>Polarized, UV Protection, Riding Glasses Wayfa...</td>\n",
       "      <td>‚Çπ210</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Brand                                Product_Description   Price\n",
       "0            VOYAGE    Polarized, UV Protection Sports Sunglasses (55)  ‚Çπ1,429\n",
       "1   Lenskart STUDIO   Polarized, UV Protection Aviator Sunglasses (51)  ‚Çπ1,429\n",
       "2              SRPM             UV Protection Wayfarer Sunglasses (50)    ‚Çπ149\n",
       "3         Elligator         UV Protection Retro Square Sunglasses (54)    ‚Çπ149\n",
       "4     VINCENT CHASE  by Lenskart Polarized, UV Protection Wayfarer ...    ‚Çπ499\n",
       "..              ...                                                ...     ...\n",
       "95          ROADWAY   UV Protection Rectangular Sunglasses (Free Size)    ‚Çπ179\n",
       "96           GANSTA  UV Protection Wayfarer, Over-sized Sunglasses ...    ‚Çπ292\n",
       "97      Eyewearlabs            UV Protection Butterfly Sunglasses (60)  ‚Çπ1,236\n",
       "98          Bembika             UV Protection Wayfarer Sunglasses (50)    ‚Çπ189\n",
       "99           PIRASO  Polarized, UV Protection, Riding Glasses Wayfa...    ‚Çπ210\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 323,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = 0\n",
    "end = 3\n",
    "\n",
    "for page in range(start,end):\n",
    "    br = driver.find_elements(By.XPATH, '//div[@class=\"_2WkVRV\"]')\n",
    "    for i in br:\n",
    "        brand.append(i.text)\n",
    "        \n",
    "    prod = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for p in prod:\n",
    "        prod_desc.append(p.text)\n",
    "    \n",
    "    pr = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for p in pr:\n",
    "        price.append(p.text)\n",
    "\n",
    "da = {'Brand': brand[:100],\n",
    "     'Product_Description':prod_desc[:100],\n",
    "     'Price':price[:100]}\n",
    "\n",
    "df = pd.DataFrame(da)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65497058",
   "metadata": {},
   "source": [
    "**Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone. You have to go the link: https://www.flipkart.com/apple-iphone-11-black-64-gb/product- reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market place=FLIPKART**\n",
    "            \n",
    "As shown in the above page you have to scrape the tick marked attributes. These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "141da087",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "aef53ea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/apple-iphone-11-black-64-gb/product-reviews/itm4e5041ba101fd?pid=MOBFWQ6BXGJCEYNY&lid=LSTMOBFWQ6BXGJCEYNYZXSHRJ&market place=FLIPKART')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "fb83622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rating = []\n",
    "summary = []\n",
    "review = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "b52967c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rating</th>\n",
       "      <th>Review Summary</th>\n",
       "      <th>Full Review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>Worth every penny</td>\n",
       "      <td>Feeling awesome after getting the delivery of ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>Best in the market!</td>\n",
       "      <td>Good Camera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>Wonderful</td>\n",
       "      <td>This is amazing at all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>Classy product</td>\n",
       "      <td>Camera is awesome\\nBest battery backup\\nA perf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific</td>\n",
       "      <td>Very very good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>5</td>\n",
       "      <td>Terrific purchase</td>\n",
       "      <td>Value for money üòç</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>Photos super</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>5</td>\n",
       "      <td>Perfect product!</td>\n",
       "      <td>V Good all</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>5</td>\n",
       "      <td>Just wow!</td>\n",
       "      <td>Perfect Product!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>5</td>\n",
       "      <td>Must buy!</td>\n",
       "      <td>It‚Äôs really awesome</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rating       Review Summary  \\\n",
       "0       5    Worth every penny   \n",
       "1       5  Best in the market!   \n",
       "2       5            Wonderful   \n",
       "3       5       Classy product   \n",
       "4       5             Terrific   \n",
       "..    ...                  ...   \n",
       "95      5    Terrific purchase   \n",
       "96      5     Perfect product!   \n",
       "97      5     Perfect product!   \n",
       "98      5            Just wow!   \n",
       "99      5            Must buy!   \n",
       "\n",
       "                                          Full Review  \n",
       "0   Feeling awesome after getting the delivery of ...  \n",
       "1                                         Good Camera  \n",
       "2                              This is amazing at all  \n",
       "3   Camera is awesome\\nBest battery backup\\nA perf...  \n",
       "4                                      Very very good  \n",
       "..                                                ...  \n",
       "95                                  Value for money üòç  \n",
       "96                                       Photos super  \n",
       "97                                         V Good all  \n",
       "98                                  Perfect Product!!  \n",
       "99                                It‚Äôs really awesome  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = 0\n",
    "end = 3\n",
    "\n",
    "for page in range(start,end):\n",
    "    \n",
    "    rat = driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')\n",
    "    for r in rat:\n",
    "        rating.append(r.text)\n",
    "    \n",
    "    sum = driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')\n",
    "    for s in sum:\n",
    "        summary.append(s.text)\n",
    "    \n",
    "    rev = driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]/div/div')\n",
    "    for r in rev:\n",
    "        review.append(r.text)\n",
    "d1 = {'Rating':rating[:100],\n",
    "     'Review Summary': summary[:100],\n",
    "     'Full Review':review[:100]}\n",
    "\n",
    "df= pd.DataFrame(d1)\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ee3506",
   "metadata": {},
   "source": [
    "**Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for ‚Äúsneakers‚Äù in the search field.\n",
    "You have to scrape 3 attributes of each sneaker:**\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the above attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "29ff58e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "41dab4f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = driver.find_element(By.XPATH,'/html/body/div[1]/div/div[1]/div/div/div/div/div[1]/div/div[1]/div/div[1]/div[1]/header/div[1]/div[2]/form/div/div/input')\n",
    "s1.send_keys('sneakers')\n",
    "s1.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "d27f2876",
   "metadata": {},
   "outputs": [],
   "source": [
    "brand = []\n",
    "prod_desc = []\n",
    "price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "1848b614",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Brand</th>\n",
       "      <th>Product Description</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BIRDE</td>\n",
       "      <td>Pack Of 2 Combo Comfortable Lightweight Regula...</td>\n",
       "      <td>‚Çπ521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aadi</td>\n",
       "      <td>Lightweight,Comfort,Summer,Trendy,Walking,Outd...</td>\n",
       "      <td>‚Çπ249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>URBANBOX</td>\n",
       "      <td>Trending Stylish Casual Outdoor Sneakers Shoes...</td>\n",
       "      <td>‚Çπ299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Modern Trendy Shoes Sneakers For Men</td>\n",
       "      <td>‚Çπ299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deals4you</td>\n",
       "      <td>Sneakers For Women</td>\n",
       "      <td>‚Çπ399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>asian</td>\n",
       "      <td>FLYING FURY Sneakers For Men</td>\n",
       "      <td>‚Çπ1,039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>BRUTON</td>\n",
       "      <td>Pack Of 2 Combo Comfortable Lightweight Regula...</td>\n",
       "      <td>‚Çπ537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>TERFILL</td>\n",
       "      <td>Lightweight,Comfort,Summer,Trendy,Walking,Outd...</td>\n",
       "      <td>‚Çπ499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>ATOM</td>\n",
       "      <td>Trending Stylish Casual Outdoor Sneakers Shoes...</td>\n",
       "      <td>‚Çπ1,339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>streetLOOK</td>\n",
       "      <td>Modern Trendy Shoes Sneakers For Men</td>\n",
       "      <td>‚Çπ494</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Brand                                Product Description   Price\n",
       "0        BIRDE  Pack Of 2 Combo Comfortable Lightweight Regula...    ‚Çπ521\n",
       "1         aadi  Lightweight,Comfort,Summer,Trendy,Walking,Outd...    ‚Çπ249\n",
       "2     URBANBOX  Trending Stylish Casual Outdoor Sneakers Shoes...    ‚Çπ299\n",
       "3       BRUTON               Modern Trendy Shoes Sneakers For Men    ‚Çπ299\n",
       "4    Deals4you                                 Sneakers For Women    ‚Çπ399\n",
       "..         ...                                                ...     ...\n",
       "95       asian                       FLYING FURY Sneakers For Men  ‚Çπ1,039\n",
       "96      BRUTON  Pack Of 2 Combo Comfortable Lightweight Regula...    ‚Çπ537\n",
       "97     TERFILL  Lightweight,Comfort,Summer,Trendy,Walking,Outd...    ‚Çπ499\n",
       "98        ATOM  Trending Stylish Casual Outdoor Sneakers Shoes...  ‚Çπ1,339\n",
       "99  streetLOOK               Modern Trendy Shoes Sneakers For Men    ‚Çπ494\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 373,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = 0\n",
    "end = 3\n",
    "\n",
    "for page in range(start,end):\n",
    "    br = driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for b in br:\n",
    "        brand.append(b.text)\n",
    "    \n",
    "    pro = driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for pr in pro:\n",
    "        prod_desc.append(pr.text)\n",
    "    \n",
    "    pric = driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for p in pric:\n",
    "        price.append(p.text)\n",
    "\n",
    "d2 = {'Brand':brand[:100],\n",
    "     'Product Description':prod_desc[:100],\n",
    "     'Price':price[:100]}\n",
    "\n",
    "df = pd.DataFrame(d2)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f9e206",
   "metadata": {},
   "source": [
    "**Q7: Go to webpage https://www.amazon.in/ Enter ‚ÄúLaptop‚Äù in the search field and then click the search icon. Then set CPU Type filter to ‚ÄúIntel Core i7‚Äù as shown in the below image:\n",
    "    After setting the filters scrape first 10 laptops data. You have to scrape 3 attributes for each laptop:**\n",
    "1. Title\n",
    "2. Ratings\n",
    "3. Price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "a9352b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.amazon.in/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "60d790f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = driver.find_element(By.XPATH,'/html/body/div[1]/header/div/div[1]/div[2]/div/form/div[2]/div[1]/input')\n",
    "s3.send_keys('Laptop')\n",
    "s3.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "fca880d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "CPU_filter = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/div[19]/span')\n",
    "intel = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div[2]/div/div[3]/span/div[1]/div/div/div[6]/ul[19]/span/span[11]/li/span/a/span')\n",
    "intel.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "d852591c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSI</td>\n",
       "      <td>58</td>\n",
       "      <td>54,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>414</td>\n",
       "      <td>64,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lenovo</td>\n",
       "      <td>432</td>\n",
       "      <td>62,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acer</td>\n",
       "      <td>115</td>\n",
       "      <td>1,41,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ASUS</td>\n",
       "      <td>178</td>\n",
       "      <td>77,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>HP</td>\n",
       "      <td>138</td>\n",
       "      <td>1,10,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>HP</td>\n",
       "      <td>681</td>\n",
       "      <td>78,990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HP</td>\n",
       "      <td>1</td>\n",
       "      <td>84,899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Lenovo</td>\n",
       "      <td>22</td>\n",
       "      <td>1,09,190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Acer</td>\n",
       "      <td>65</td>\n",
       "      <td>54,990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Title Ratings     Price\n",
       "0     MSI      58    54,990\n",
       "1    ASUS     414    64,990\n",
       "2  Lenovo     432    62,990\n",
       "3    Acer     115  1,41,990\n",
       "4    ASUS     178    77,990\n",
       "5      HP     138  1,10,990\n",
       "6      HP     681    78,990\n",
       "7      HP       1    84,899\n",
       "8  Lenovo      22  1,09,190\n",
       "9    Acer      65    54,990"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laptops = []\n",
    "ratings = []\n",
    "price = []\n",
    "\n",
    "lap = driver.find_elements(By.XPATH,'//span[@class=\"a-size-medium a-color-base\"]')\n",
    "for l in lap:\n",
    "    laptops.append(l.text)\n",
    "\n",
    "rating = driver.find_elements(By.XPATH,'//span[@class=\"a-size-base s-underline-text\"]')\n",
    "for r in rating:\n",
    "    ratings.append(r.text)\n",
    "\n",
    "pri = driver.find_elements(By.XPATH,'//span[@class=\"a-price-whole\"]')\n",
    "for p in pri:\n",
    "    price.append(p.text)\n",
    "\n",
    "frame = {'Title':laptops[:10],\n",
    "        'Ratings':ratings[:10],\n",
    "        'Price':price[:10]}\n",
    "\n",
    "df = pd.DataFrame(frame)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca0d353a",
   "metadata": {},
   "source": [
    "**Q8: Write a python program to scrape data for Top 1000 Quotes of All Time.\n",
    "The above task will be done in following steps:**\n",
    "1. First get the webpagehttps://www.azquotes.com/\n",
    "2. Click on Top Quotes\n",
    "3. Than scrap a) Quote b) Author c) Type Of Quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "id": "659d1634",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.azquotes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "id": "6750d264",
   "metadata": {},
   "outputs": [],
   "source": [
    "top = driver.find_element(By.XPATH,'/html/body/div[1]/div[1]/div[1]/div/div[3]/ul/li[5]/a')\n",
    "top.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "id": "03b2a459",
   "metadata": {},
   "outputs": [],
   "source": [
    "quote = []\n",
    "author = []\n",
    "typeofquote = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "47fbb174",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quote</th>\n",
       "      <th>Author</th>\n",
       "      <th>Type of Quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The essence of strategy is choosing what not t...</td>\n",
       "      <td>Michael Porter</td>\n",
       "      <td>Essence, Deep Thought, Transcendentalism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>One cannot and must not try to erase the past ...</td>\n",
       "      <td>Golda Meir</td>\n",
       "      <td>Inspiration, Past, Trying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Patriotism means to stand by the country. It d...</td>\n",
       "      <td>Theodore Roosevelt</td>\n",
       "      <td>Country, Peace, War</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Death is something inevitable. When a man has ...</td>\n",
       "      <td>Nelson Mandela</td>\n",
       "      <td>Inspirational, Motivational, Death</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You have to love a nation that celebrates its ...</td>\n",
       "      <td>Erma Bombeck</td>\n",
       "      <td>4th Of July, Food, Patriotic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>When the going gets weird, the weird turn pro.</td>\n",
       "      <td>Hunter S. Thompson</td>\n",
       "      <td>Music, Sports, Hunting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>When a train goes through a tunnel and it gets...</td>\n",
       "      <td>Corrie Ten Boom</td>\n",
       "      <td>Trust, Encouraging, Uplifting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>If you think you are too small to make a diffe...</td>\n",
       "      <td>Dalai Lama</td>\n",
       "      <td>Inspirational, Funny, Change</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>God doesn't require us to succeed, he only req...</td>\n",
       "      <td>Mother Teresa</td>\n",
       "      <td>Success, God, Mother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>Change your thoughts and you change your world.</td>\n",
       "      <td>Norman Vincent Peale</td>\n",
       "      <td>Inspirational, Motivational, Change</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Quote                Author  \\\n",
       "0    The essence of strategy is choosing what not t...        Michael Porter   \n",
       "1    One cannot and must not try to erase the past ...            Golda Meir   \n",
       "2    Patriotism means to stand by the country. It d...    Theodore Roosevelt   \n",
       "3    Death is something inevitable. When a man has ...        Nelson Mandela   \n",
       "4    You have to love a nation that celebrates its ...          Erma Bombeck   \n",
       "..                                                 ...                   ...   \n",
       "995     When the going gets weird, the weird turn pro.    Hunter S. Thompson   \n",
       "996  When a train goes through a tunnel and it gets...       Corrie Ten Boom   \n",
       "997  If you think you are too small to make a diffe...            Dalai Lama   \n",
       "998  God doesn't require us to succeed, he only req...         Mother Teresa   \n",
       "999    Change your thoughts and you change your world.  Norman Vincent Peale   \n",
       "\n",
       "                                Type of Quote  \n",
       "0    Essence, Deep Thought, Transcendentalism  \n",
       "1                   Inspiration, Past, Trying  \n",
       "2                         Country, Peace, War  \n",
       "3          Inspirational, Motivational, Death  \n",
       "4                4th Of July, Food, Patriotic  \n",
       "..                                        ...  \n",
       "995                    Music, Sports, Hunting  \n",
       "996             Trust, Encouraging, Uplifting  \n",
       "997              Inspirational, Funny, Change  \n",
       "998                      Success, God, Mother  \n",
       "999       Inspirational, Motivational, Change  \n",
       "\n",
       "[1000 rows x 3 columns]"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start =0\n",
    "end =4\n",
    "\n",
    "for page in range(start,end):\n",
    "    qt = driver.find_elements(By.XPATH,'//a[@class=\"title\"]')\n",
    "    for q in qt:\n",
    "        quote.append(q.text)\n",
    "    \n",
    "    auth = driver.find_elements(By.XPATH,'//div[@class=\"author\"]')\n",
    "    for a in auth:\n",
    "        author.append(a.text)\n",
    "    \n",
    "    type1 = driver.find_elements(By.XPATH,'//div[@class=\"tags\"]')\n",
    "    for t in type1:\n",
    "        typeofquote.append(t.text)\n",
    "d5 = {'Quote':quote[:1000],\n",
    "     'Author':author[:1000],\n",
    "     'Type of Quote':typeofquote[:1000]}\n",
    "\n",
    "df = pd.DataFrame(d5)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000da847",
   "metadata": {},
   "source": [
    "**Q9: Write a python program to display list of respected former Prime Ministers of India(i.e. Name, Born-Dead, Term of office, Remarks) from https://www.jagranjosh.com/.\n",
    "This task will be done in following steps:**\n",
    "1. First get the webpagehttps://www.jagranjosh.com/\n",
    "2. Then You have to click on the GK option\n",
    "3. Then click on the List of all Prime Ministers of India\n",
    "4. Then scrap the mentioned data and make theDataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "id": "aa767641",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "6a920817",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.jagranjosh.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "id": "32b5f7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "option = driver.find_element(By.XPATH,'/html/body/div/header/nav/div/div/div[3]/ul/li[3]/a')\n",
    "option.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "id": "76aae57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "list1 = driver.find_element(By.XPATH,'/html/body/div[1]/div[8]/section[8]/div/ul/li[10]/a')\n",
    "list1.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "96e26a81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Gulzarilal Nanda (Acting)']"
      ]
     },
     "execution_count": 444,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prime_list = []\n",
    "\n",
    "list2 = driver.find_elements(By.XPATH,'//*[@id=\"itemdiv\"]/div[3]/div[6]/div/table/tbody/tr[3]/td[2]/div')\n",
    "for l in list2:\n",
    "    prime_list.append(l.text)\n",
    "prime_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5595817",
   "metadata": {},
   "source": [
    "**Q10: Write a python program to display list of 50 Most expensive cars in the world (i.e. Car name and Price) from https://www.motor1.com/\n",
    "This task will be done in following steps:**\n",
    "1. First get the webpage https://www.motor1.com/\n",
    "2. Then You have to type in the search bar ‚Äô50 most expensive cars‚Äô\n",
    "3. Then click on 50 most expensive cars in the world..\n",
    "4. Then scrap the mentioned data and make the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "id": "ff341799",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.motor1.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "id": "fbbae58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = driver.find_element(By.XPATH,'/html/body/div[10]/div[2]/div/div/div[3]/div/div/div/form/input')\n",
    "cars.send_keys('50 most expensive cars')\n",
    "cars.submit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "id": "66339469",
   "metadata": {},
   "outputs": [],
   "source": [
    "car50 = driver.find_element(By.XPATH,'/html/body/div[10]/div[9]/div/div[1]/div/div/div[2]/div/div[1]/h3/a')\n",
    "car50.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "id": "23a319c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "car_name = []\n",
    "price = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4944cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "car = driver.find_elements(By.XPATH,'//h3[@class=\"subheader\"]/span')\n",
    "for c in car:\n",
    "    car_name.append(c.text)\n",
    "\n",
    "price1 = driver.find_elements(By.XPATH,'')\n",
    "for p in price1:\n",
    "    price.append(p.text)\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecec733b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae4444b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702abe3f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
