{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4763a539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException,ElementNotVisibleException,ElementClickInterceptedException\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "import re\n",
    "import time\n",
    "import warnings\n",
    "import requests\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6410219",
   "metadata": {},
   "source": [
    "**1. Scrape the details of most viewed videos on YouTube from Wikipedia. Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos You need to find following details:**\n",
    "A) Rank\n",
    "B) Name\n",
    "C) Artist\n",
    "D) Upload date\n",
    "E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8be2ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Upload Date</th>\n",
       "      <th>Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>June 17, 2016</td>\n",
       "      <td>11.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>January 12, 2017</td>\n",
       "      <td>7.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>October 8, 2016</td>\n",
       "      <td>6.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Shape of You\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>January 30, 2017</td>\n",
       "      <td>5.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"See You Again\"</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>April 6, 2015</td>\n",
       "      <td>5.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"Bath Song\"</td>\n",
       "      <td>Cocomelon â€“ Nursery Rhymes</td>\n",
       "      <td>May 2, 2018</td>\n",
       "      <td>5.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>March 6, 2014</td>\n",
       "      <td>4.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Uptown Funk\"</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>November 19, 2014</td>\n",
       "      <td>4.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Learning Colors â€“ Colorful Eggs on a Farm\"</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>February 27, 2018</td>\n",
       "      <td>4.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Gangnam Style\"</td>\n",
       "      <td>Psy</td>\n",
       "      <td>July 15, 2012</td>\n",
       "      <td>4.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Masha and the Bear â€“ Recipe for Disaster\"</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>January 31, 2012</td>\n",
       "      <td>4.51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Wheels on the Bus\"</td>\n",
       "      <td>Cocomelon â€“ Nursery Rhymes</td>\n",
       "      <td>May 24, 2018</td>\n",
       "      <td>4.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>April 5, 2018</td>\n",
       "      <td>4.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Sugar\"</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>January 14, 2015</td>\n",
       "      <td>3.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Roar\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>September 5, 2013</td>\n",
       "      <td>3.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Counting Stars\"</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>May 31, 2013</td>\n",
       "      <td>3.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Sorry\"</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>October 22, 2015</td>\n",
       "      <td>3.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Axel F\"</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>June 16, 2009</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Thinking Out Loud\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>October 7, 2014</td>\n",
       "      <td>3.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"</td>\n",
       "      <td>Cocomelon â€“ Nursery Rhymes</td>\n",
       "      <td>June 25, 2018</td>\n",
       "      <td>3.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Dark Horse\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>February 20, 2014</td>\n",
       "      <td>3.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Faded\"</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>December 3, 2015</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Girls Like You\"</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>May 31, 2018</td>\n",
       "      <td>3.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Let Her Go\"</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>July 25, 2012</td>\n",
       "      <td>3.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Bailando\"</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>April 11, 2014</td>\n",
       "      <td>3.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Lean On\"</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>March 22, 2015</td>\n",
       "      <td>3.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Perfect\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>November 9, 2017</td>\n",
       "      <td>3.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>June 4, 2010</td>\n",
       "      <td>3.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Shake It Off\"</td>\n",
       "      <td>Taylor Swift</td>\n",
       "      <td>August 18, 2014</td>\n",
       "      <td>3.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"</td>\n",
       "      <td>Kiddiestv Hindi â€“ Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>January 26, 2018</td>\n",
       "      <td>3.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                   Video Name  \\\n",
       "0    1.                           \"Baby Shark Dance\"   \n",
       "1    2.                                  \"Despacito\"   \n",
       "2    3.                       \"Johny Johny Yes Papa\"   \n",
       "3    4.                               \"Shape of You\"   \n",
       "4    5.                              \"See You Again\"   \n",
       "5    6.                                  \"Bath Song\"   \n",
       "6    7.                \"Phonics Song with Two Words\"   \n",
       "7    8.                                \"Uptown Funk\"   \n",
       "8    9.  \"Learning Colors â€“ Colorful Eggs on a Farm\"   \n",
       "9   10.                              \"Gangnam Style\"   \n",
       "10  11.   \"Masha and the Bear â€“ Recipe for Disaster\"   \n",
       "11  12.                          \"Wheels on the Bus\"   \n",
       "12  13.                             \"Dame Tu Cosita\"   \n",
       "13  14.                                      \"Sugar\"   \n",
       "14  15.                                       \"Roar\"   \n",
       "15  16.                             \"Counting Stars\"   \n",
       "16  17.                                      \"Sorry\"   \n",
       "17  18.                                     \"Axel F\"   \n",
       "18  18.                          \"Thinking Out Loud\"   \n",
       "19  20.                        \"Baa Baa Black Sheep\"   \n",
       "20  21.                                 \"Dark Horse\"   \n",
       "21  22.                                      \"Faded\"   \n",
       "22  23.                             \"Girls Like You\"   \n",
       "23  24.                                 \"Let Her Go\"   \n",
       "24  25.                                   \"Bailando\"   \n",
       "25  26.                                    \"Lean On\"   \n",
       "26  27.                                    \"Perfect\"   \n",
       "27  28.           \"Waka Waka (This Time for Africa)\"   \n",
       "28  29.                               \"Shake It Off\"   \n",
       "29  30.          \"Humpty the train on a fruits ride\"   \n",
       "\n",
       "                                           Artist        Upload Date  Views  \n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories      June 17, 2016  11.24  \n",
       "1                                      Luis Fonsi   January 12, 2017   7.96  \n",
       "2                                     LooLoo Kids    October 8, 2016   6.44  \n",
       "3                                      Ed Sheeran   January 30, 2017   5.80  \n",
       "4                                     Wiz Khalifa      April 6, 2015   5.62  \n",
       "5                      Cocomelon â€“ Nursery Rhymes        May 2, 2018   5.59  \n",
       "6                                       ChuChu TV      March 6, 2014   4.85  \n",
       "7                                     Mark Ronson  November 19, 2014   4.68  \n",
       "8                                     Miroshka TV  February 27, 2018   4.61  \n",
       "9                                             Psy      July 15, 2012   4.53  \n",
       "10                                     Get Movies   January 31, 2012   4.51  \n",
       "11                     Cocomelon â€“ Nursery Rhymes       May 24, 2018   4.31  \n",
       "12                                      El Chombo      April 5, 2018   4.05  \n",
       "13                                       Maroon 5   January 14, 2015   3.75  \n",
       "14                                     Katy Perry  September 5, 2013   3.64  \n",
       "15                                    OneRepublic       May 31, 2013   3.63  \n",
       "16                                  Justin Bieber   October 22, 2015   3.58  \n",
       "17                                     Crazy Frog      June 16, 2009   3.49  \n",
       "18                                     Ed Sheeran    October 7, 2014   3.49  \n",
       "19                     Cocomelon â€“ Nursery Rhymes      June 25, 2018   3.35  \n",
       "20                                     Katy Perry  February 20, 2014   3.34  \n",
       "21                                    Alan Walker   December 3, 2015   3.33  \n",
       "22                                       Maroon 5       May 31, 2018   3.33  \n",
       "23                                      Passenger      July 25, 2012   3.29  \n",
       "24                               Enrique Iglesias     April 11, 2014   3.26  \n",
       "25                                    Major Lazer     March 22, 2015   3.25  \n",
       "26                                     Ed Sheeran   November 9, 2017   3.24  \n",
       "27                                        Shakira       June 4, 2010   3.23  \n",
       "28                                   Taylor Swift    August 18, 2014   3.20  \n",
       "29  Kiddiestv Hindi â€“ Nursery Rhymes & Kids Songs   January 26, 2018   3.14  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos'\n",
    "driver=webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(3)\n",
    "rank=[]\n",
    "name=[]\n",
    "artist=[]\n",
    "upload_date=[]\n",
    "views=[]\n",
    "\n",
    "rank_tag=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[1]')\n",
    "try:\n",
    "    for i in rank_tag[0:30]:\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    rank.append(\"-\")\n",
    "except ElementNotVisibleException:\n",
    "    rank.append(\"--\")\n",
    "    \n",
    "name_tag=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[2]')\n",
    "try:\n",
    "    for i in name_tag[0:30]:\n",
    "        v_name=i.text.split('[')\n",
    "        name.append(v_name[0])\n",
    "except NoSuchElementException:\n",
    "    name.append(\"-\")\n",
    "except ElementNotVisibleException:\n",
    "    name.append(\"--\")\n",
    "    \n",
    "artist_tag=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[3]')\n",
    "try:\n",
    "    for i in artist_tag[0:30]:\n",
    "        artist.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    artist.append(\"-\")\n",
    "    \n",
    "date_tag=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[5]')\n",
    "try:\n",
    "    for i in date_tag[0:30]:\n",
    "        upload_date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    upload_date.append(\"-\")\n",
    "    \n",
    "view_tag=driver.find_elements(By.XPATH,'//table[@class=\"wikitable sortable jquery-tablesorter\"]/tbody/tr/td[4]')\n",
    "try:\n",
    "    for i in view_tag[0:30]:\n",
    "        views.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    views.append(\"-\")\n",
    "    \n",
    "driver.close()\n",
    "\n",
    "most_viewed=pd.DataFrame({'Rank':rank,'Video Name':name,'Artist':artist,'Upload Date':upload_date,'Views':views})\n",
    "most_viewed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a5c7f16",
   "metadata": {},
   "source": [
    "**2. Scrape the details team Indiaâ€™s international fixtures from bcci.tv.\n",
    "Url = https://www.bcci.tv/.\n",
    "You need to find following details:**\n",
    "A) Series\n",
    "B) Place\n",
    "C) Date\n",
    "D) Time\n",
    "Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b001cc8d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//a[normalize-space()='INTERNATIONAL']\"}\n  (Session info: chrome=122.0.6261.57); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF6BD7C4C82+3505170]\n\t(No symbol) [0x00007FF6BD3F0852]\n\t(No symbol) [0x00007FF6BD2A4145]\n\t(No symbol) [0x00007FF6BD2E9ADD]\n\t(No symbol) [0x00007FF6BD2E9C1C]\n\t(No symbol) [0x00007FF6BD32AB27]\n\t(No symbol) [0x00007FF6BD30BECF]\n\t(No symbol) [0x00007FF6BD3283B2]\n\t(No symbol) [0x00007FF6BD30BC33]\n\t(No symbol) [0x00007FF6BD2DD618]\n\t(No symbol) [0x00007FF6BD2DE6B1]\n\tGetHandleVerifier [0x00007FF6BD7F67DD+3708781]\n\tGetHandleVerifier [0x00007FF6BD84FC5D+4074477]\n\tGetHandleVerifier [0x00007FF6BD847DDF+4042095]\n\tGetHandleVerifier [0x00007FF6BD51A136+708806]\n\t(No symbol) [0x00007FF6BD3FCB0F]\n\t(No symbol) [0x00007FF6BD3F7D14]\n\t(No symbol) [0x00007FF6BD3F7E6C]\n\t(No symbol) [0x00007FF6BD3E79A4]\n\tBaseThreadInitThunk [0x00007FFC36AD257D+29]\n\tRtlUserThreadStart [0x00007FFC37E0AA58+40]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m#Click on INTERNATIONAL navigation\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m \u001b[43mdriver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfind_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mXPATH\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m//a[normalize-space()=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mINTERNATIONAL\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mclick()\n\u001b[0;32m     17\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:741\u001b[0m, in \u001b[0;36mWebDriver.find_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    738\u001b[0m     by \u001b[38;5;241m=\u001b[39m By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR\n\u001b[0;32m    739\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m[name=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m--> 741\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCommand\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFIND_ELEMENT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43musing\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mby\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalue\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py:347\u001b[0m, in \u001b[0;36mWebDriver.execute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    345\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_executor\u001b[38;5;241m.\u001b[39mexecute(driver_command, params)\n\u001b[0;32m    346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response:\n\u001b[1;32m--> 347\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_handler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcheck_response\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    348\u001b[0m     response[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_unwrap_value(response\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    349\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py:229\u001b[0m, in \u001b[0;36mErrorHandler.check_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    227\u001b[0m         alert_text \u001b[38;5;241m=\u001b[39m value[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124malert\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtext\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace, alert_text)  \u001b[38;5;66;03m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception_class(message, screen, stacktrace)\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//a[normalize-space()='INTERNATIONAL']\"}\n  (Session info: chrome=122.0.6261.57); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#no-such-element-exception\nStacktrace:\n\tGetHandleVerifier [0x00007FF6BD7C4C82+3505170]\n\t(No symbol) [0x00007FF6BD3F0852]\n\t(No symbol) [0x00007FF6BD2A4145]\n\t(No symbol) [0x00007FF6BD2E9ADD]\n\t(No symbol) [0x00007FF6BD2E9C1C]\n\t(No symbol) [0x00007FF6BD32AB27]\n\t(No symbol) [0x00007FF6BD30BECF]\n\t(No symbol) [0x00007FF6BD3283B2]\n\t(No symbol) [0x00007FF6BD30BC33]\n\t(No symbol) [0x00007FF6BD2DD618]\n\t(No symbol) [0x00007FF6BD2DE6B1]\n\tGetHandleVerifier [0x00007FF6BD7F67DD+3708781]\n\tGetHandleVerifier [0x00007FF6BD84FC5D+4074477]\n\tGetHandleVerifier [0x00007FF6BD847DDF+4042095]\n\tGetHandleVerifier [0x00007FF6BD51A136+708806]\n\t(No symbol) [0x00007FF6BD3FCB0F]\n\t(No symbol) [0x00007FF6BD3F7D14]\n\t(No symbol) [0x00007FF6BD3F7E6C]\n\t(No symbol) [0x00007FF6BD3E79A4]\n\tBaseThreadInitThunk [0x00007FFC36AD257D+29]\n\tRtlUserThreadStart [0x00007FFC37E0AA58+40]\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.bcci.tv'\n",
    "driver=webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "driver.get(url)\n",
    "\n",
    "match_title=[]\n",
    "series=[]\n",
    "place=[]\n",
    "date=[]\n",
    "m_time=[]\n",
    "\n",
    "time.sleep(3)\n",
    "\n",
    "#Click on INTERNATIONAL navigation\n",
    "driver.find_element(By.XPATH,\"//a[normalize-space()='INTERNATIONAL']\").click()\n",
    "\n",
    "time.sleep(3)\n",
    "for _ in range(1):\n",
    "    driver.execute_script(\"window.scrollBy(0,1000)\")\n",
    "    time.sleep(3)\n",
    "    try:\n",
    "        driver.find_element(By.XPATH,'/html[1]/body[1]/div[2]/div[2]/div[1]/div[1]/div[1]/div[2]/div[3]/div[2]/div[1]/button[1]').click()\n",
    "    except NoSuchElementException:\n",
    "        print(\"NoSuchElementException \")\n",
    "    \n",
    "title_tag=driver.find_elements(By.XPATH,'//span[@class=\"ng-binding\"]')\n",
    "try:\n",
    "    for i in title_tag:\n",
    "        match_title.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    match_title.append(\"-\")\n",
    "match_title\n",
    "\n",
    "\n",
    "series_tag=driver.find_elements(By.XPATH,'//div[@class=\"fix-place ng-binding ng-scope\"]')\n",
    "try:\n",
    "    for i in series_tag:\n",
    "        s_tag=i.text.split('-')\n",
    "        series.append(s_tag[0])\n",
    "except NoSuchElementException:\n",
    "    series.append(\"-\")\n",
    "    \n",
    "\n",
    "place_tag=driver.find_elements(By.XPATH,'//div[@class=\"fix-place ng-binding ng-scope\"]')\n",
    "try:\n",
    "    for i in place_tag:\n",
    "        p_tag=i.text.split('-')\n",
    "        place.append(p_tag[1])\n",
    "except NoSuchElementException:\n",
    "    place.append(\"-\")\n",
    "    \n",
    "\n",
    "\n",
    "date_tag=driver.find_elements(By.XPATH,'//h5[@class=\"ng-binding\"]')\n",
    "try:\n",
    "    for i in date_tag:\n",
    "        date.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    date.append(\"-\")\n",
    "    \n",
    "\n",
    "time_tag=driver.find_elements(By.XPATH,'//h5[@class=\"text-right ng-binding\"]')\n",
    "try:\n",
    "    for i in time_tag:\n",
    "        m_time.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    m_time.append(\"-\")\n",
    "    \n",
    "driver.close()\n",
    "\n",
    "\n",
    "international_fixtures=pd.DataFrame({'Match Title':match_title,'Series':series,'Place':place,'Date':date,'Time':m_time})\n",
    "international_fixtures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "406d242a",
   "metadata": {},
   "source": [
    "**3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "Url = http://statisticstimes.com/\n",
    "You have to find following details:** \n",
    "A) Rank\n",
    "B) State\n",
    "C) GSDP(18-19)- at current prices\n",
    "D) GSDP(19-20)- at current prices\n",
    "E) Share(18-19)\n",
    "F) GDP($ billion)\n",
    "Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3050331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP 19-20</th>\n",
       "      <th>GSDP 18-19</th>\n",
       "      <th>Share 18-19</th>\n",
       "      <th>GDP billion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>-</td>\n",
       "      <td>3,108,022</td>\n",
       "      <td>13.24%</td>\n",
       "      <td>417.163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>2,364,514</td>\n",
       "      <td>2,071,286</td>\n",
       "      <td>8.82%</td>\n",
       "      <td>278.011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>2,257,575</td>\n",
       "      <td>1,974,532</td>\n",
       "      <td>8.41%</td>\n",
       "      <td>265.024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>2,241,368</td>\n",
       "      <td>1,962,725</td>\n",
       "      <td>8.36%</td>\n",
       "      <td>263.440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>-</td>\n",
       "      <td>1,937,066</td>\n",
       "      <td>8.25%</td>\n",
       "      <td>259.996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,554,992</td>\n",
       "      <td>1,363,926</td>\n",
       "      <td>5.81%</td>\n",
       "      <td>183.068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>1,413,620</td>\n",
       "      <td>1,218,193</td>\n",
       "      <td>5.19%</td>\n",
       "      <td>163.507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>1,322,821</td>\n",
       "      <td>1,136,137</td>\n",
       "      <td>4.84%</td>\n",
       "      <td>152.494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>1,317,728</td>\n",
       "      <td>1,133,837</td>\n",
       "      <td>4.83%</td>\n",
       "      <td>152.185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>1,313,391</td>\n",
       "      <td>1,128,907</td>\n",
       "      <td>4.81%</td>\n",
       "      <td>151.523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>-</td>\n",
       "      <td>932,470</td>\n",
       "      <td>3.97%</td>\n",
       "      <td>125.157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>1,043,759</td>\n",
       "      <td>904,642</td>\n",
       "      <td>3.85%</td>\n",
       "      <td>121.422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>994,154</td>\n",
       "      <td>870,665</td>\n",
       "      <td>3.71%</td>\n",
       "      <td>116.862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>774,869</td>\n",
       "      <td>670,881</td>\n",
       "      <td>2.86%</td>\n",
       "      <td>90.047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>751,396</td>\n",
       "      <td>650,302</td>\n",
       "      <td>2.77%</td>\n",
       "      <td>87.284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>673,107</td>\n",
       "      <td>614,227</td>\n",
       "      <td>2.62%</td>\n",
       "      <td>82.442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>493,167</td>\n",
       "      <td>412,612</td>\n",
       "      <td>1.76%</td>\n",
       "      <td>55.381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>457,608</td>\n",
       "      <td>406,416</td>\n",
       "      <td>1.73%</td>\n",
       "      <td>54.550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>393,722</td>\n",
       "      <td>358,863</td>\n",
       "      <td>1.53%</td>\n",
       "      <td>48.167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>302,621</td>\n",
       "      <td>272,159</td>\n",
       "      <td>1.16%</td>\n",
       "      <td>36.530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir-UT</td>\n",
       "      <td>227,927</td>\n",
       "      <td>199,917</td>\n",
       "      <td>0.85%</td>\n",
       "      <td>26.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>195,405</td>\n",
       "      <td>176,269</td>\n",
       "      <td>0.75%</td>\n",
       "      <td>23.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>-</td>\n",
       "      <td>82,604</td>\n",
       "      <td>0.35%</td>\n",
       "      <td>11.087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>72,636</td>\n",
       "      <td>62,550</td>\n",
       "      <td>0.27%</td>\n",
       "      <td>8.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>-</td>\n",
       "      <td>45,635</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>6.125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>-</td>\n",
       "      <td>44,238</td>\n",
       "      <td>0.19%</td>\n",
       "      <td>5.938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>42,697</td>\n",
       "      <td>38,785</td>\n",
       "      <td>0.17%</td>\n",
       "      <td>5.206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>42,756</td>\n",
       "      <td>37,557</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>5.041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>-</td>\n",
       "      <td>36,594</td>\n",
       "      <td>0.16%</td>\n",
       "      <td>4.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>-</td>\n",
       "      <td>35,124</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>-</td>\n",
       "      <td>31,913</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>-</td>\n",
       "      <td>27,824</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>10,371</td>\n",
       "      <td>0.04%</td>\n",
       "      <td>1.392</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP 19-20 GSDP 18-19 Share 18-19  \\\n",
       "0     1                Maharashtra          -  3,108,022      13.24%   \n",
       "1     2                 Tamil Nadu  2,364,514  2,071,286       8.82%   \n",
       "2     3              Uttar Pradesh  2,257,575  1,974,532       8.41%   \n",
       "3     4                  Karnataka  2,241,368  1,962,725       8.36%   \n",
       "4     5                    Gujarat          -  1,937,066       8.25%   \n",
       "5     6                West Bengal  1,554,992  1,363,926       5.81%   \n",
       "6     7                  Rajasthan  1,413,620  1,218,193       5.19%   \n",
       "7     8             Madhya Pradesh  1,322,821  1,136,137       4.84%   \n",
       "8     9             Andhra Pradesh  1,317,728  1,133,837       4.83%   \n",
       "9    10                  Telangana  1,313,391  1,128,907       4.81%   \n",
       "10   11                     Kerala          -    932,470       3.97%   \n",
       "11   12                      Delhi  1,043,759    904,642       3.85%   \n",
       "12   13                    Haryana    994,154    870,665       3.71%   \n",
       "13   14                     Odisha    774,869    670,881       2.86%   \n",
       "14   15                      Bihar    751,396    650,302       2.77%   \n",
       "15   16                     Punjab    673,107    614,227       2.62%   \n",
       "16   17                      Assam    493,167    412,612       1.76%   \n",
       "17   18               Chhattisgarh    457,608    406,416       1.73%   \n",
       "18   19                  Jharkhand    393,722    358,863       1.53%   \n",
       "19   20                Uttarakhand    302,621    272,159       1.16%   \n",
       "20   21         Jammu & Kashmir-UT    227,927    199,917       0.85%   \n",
       "21   22           Himachal Pradesh    195,405    176,269       0.75%   \n",
       "22   23                        Goa          -     82,604       0.35%   \n",
       "23   24                    Tripura     72,636     62,550       0.27%   \n",
       "24   25                 Chandigarh          -     45,635       0.19%   \n",
       "25   26                 Puducherry          -     44,238       0.19%   \n",
       "26   27                  Meghalaya     42,697     38,785       0.17%   \n",
       "27   28                     Sikkim     42,756     37,557       0.16%   \n",
       "28   29                    Manipur          -     36,594       0.16%   \n",
       "29   30          Arunachal Pradesh          -     35,124       0.15%   \n",
       "30   31                   Nagaland          -     31,913       0.14%   \n",
       "31   32                    Mizoram          -     27,824       0.12%   \n",
       "32   33  Andaman & Nicobar Islands          -     10,371       0.04%   \n",
       "\n",
       "   GDP billion  \n",
       "0      417.163  \n",
       "1      278.011  \n",
       "2      265.024  \n",
       "3      263.440  \n",
       "4      259.996  \n",
       "5      183.068  \n",
       "6      163.507  \n",
       "7      152.494  \n",
       "8      152.185  \n",
       "9      151.523  \n",
       "10     125.157  \n",
       "11     121.422  \n",
       "12     116.862  \n",
       "13      90.047  \n",
       "14      87.284  \n",
       "15      82.442  \n",
       "16      55.381  \n",
       "17      54.550  \n",
       "18      48.167  \n",
       "19      36.530  \n",
       "20      26.833  \n",
       "21      23.659  \n",
       "22      11.087  \n",
       "23       8.396  \n",
       "24       6.125  \n",
       "25       5.938  \n",
       "26       5.206  \n",
       "27       5.041  \n",
       "28       4.912  \n",
       "29       4.714  \n",
       "30       4.283  \n",
       "31       3.735  \n",
       "32       1.392  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url='https://www.statisticstimes.com'\n",
    "driver=webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "driver.get(url)\n",
    "\n",
    "time.sleep(3)\n",
    "economy = driver.find_element(By.XPATH,\"//*[@id='top']/div[2]/div[2]/button\")\n",
    "try:\n",
    "    economy.click()\n",
    "    driver.find_element(By.XPATH,'/html[1]/body[1]/div[2]/div[1]/div[2]/div[2]/div[1]/a[3]').click()\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(economy.get_attribute('href'))\n",
    "    \n",
    "time.sleep(3)\n",
    "try:\n",
    "    ads=driver.find_element(By.XPATH,'//div[@class=\"ns-dbyfr-e-19 button-common close-button\"]')\n",
    "    ads.click()\n",
    "    gdp = driver.find_element(By.XPATH,\"/html/body/div[2]/div[2]/div[2]/ul/li[1]/a\").click()\n",
    "except NoSuchElementException:\n",
    "    driver.get('https://www.statisticstimes.com/economy/india/indian-states-gdp.php')\n",
    "    \n",
    "time.sleep(3)\n",
    "\n",
    "\n",
    "rank=[]\n",
    "state=[]\n",
    "GSDP_19_20=[]\n",
    "GSDP_18_19=[]\n",
    "share_18_19=[]\n",
    "GDP_billion=[]\n",
    "\n",
    "\n",
    "state_rank=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[1]')\n",
    "try:\n",
    "    for i in state_rank:\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    rank.append(\"-\")\n",
    "    \n",
    "state_name=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[2]')\n",
    "try:\n",
    "    for i in state_name:\n",
    "        state.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    state.append(\"-\")\n",
    "        \n",
    "GSDP_19_20_tag=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[3]')\n",
    "try:\n",
    "    for i in GSDP_19_20_tag:\n",
    "        GSDP_19_20.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP_19_20.append(\"-\")\n",
    "    \n",
    "GSDP_18_19_tag=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[4]')\n",
    "try:\n",
    "    for i in GSDP_18_19_tag:\n",
    "        GSDP_18_19.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GSDP_18_19.append(\"-\")\n",
    "    \n",
    "share_18_19_tag=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[5]')\n",
    "try:\n",
    "    for i in share_18_19_tag:\n",
    "        share_18_19.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    share_18_19.append(\"-\")\n",
    "    \n",
    "GDP_billion_tag=driver.find_elements(By.XPATH,'//*[@id=\"table_id\"]/tbody/tr/td[6]')\n",
    "try:\n",
    "    for i in GDP_billion_tag:\n",
    "        GDP_billion.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    GDP_billion.append(\"-\")\n",
    "    \n",
    "    \n",
    "driver.close()\n",
    "\n",
    "StateWise_GDP=pd.DataFrame({'Rank':rank,'State':state,'GSDP 19-20':GSDP_19_20,'GSDP 18-19':GSDP_18_19,'Share 18-19':share_18_19,'GDP billion':GDP_billion})\n",
    "StateWise_GDP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1b0b01",
   "metadata": {},
   "source": [
    "**4. Scrape the details of trending repositories on Github.com.\n",
    "Url = https://github.com/**\n",
    "You have to find the following details:\n",
    "A) Repository title\n",
    "B) Repository description\n",
    "C) Contributors count\n",
    "D) Language used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "8d08551b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository_title</th>\n",
       "      <th>Repository_description</th>\n",
       "      <th>Language_used</th>\n",
       "      <th>Contributors_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUTOMATIC1111 / stable-diffusion-webui</td>\n",
       "      <td>Stable Diffusion web UI</td>\n",
       "      <td>[Python, JavaScript, Batchfile, CSS]</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sd-webui / stable-diffusion-webui</td>\n",
       "      <td>Stable Diffusion web UI</td>\n",
       "      <td>[Python, Other]</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>somebasj / ParallelsDesktopCrack</td>\n",
       "      <td>Parallels Desktop for mac Crack</td>\n",
       "      <td>[Shell]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AykutSarac / jsoncrack.com</td>\n",
       "      <td>ðŸ”® Seamlessly visualize your JSON data instantl...</td>\n",
       "      <td>[TypeScript, Other]</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>surrealdb / surrealdb</td>\n",
       "      <td>A scalable, distributed, collaborative, docume...</td>\n",
       "      <td>[Rust, Other]</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yt-dlp / yt-dlp</td>\n",
       "      <td>A youtube-dl fork with additional features and...</td>\n",
       "      <td>[Python, Other]</td>\n",
       "      <td>1,013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>termux / termux-app</td>\n",
       "      <td>Termux - a terminal emulator application for A...</td>\n",
       "      <td>[Java, C++, Other]</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>TheAlgorithms / Python</td>\n",
       "      <td>All Algorithms implemented in Python</td>\n",
       "      <td>[Python]</td>\n",
       "      <td>829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>mtdvio / every-programmer-should-know</td>\n",
       "      <td>A collection of (mostly) technical things ever...</td>\n",
       "      <td>[70, 59]</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Alcibiades-Capital / mev_bundle_generator</td>\n",
       "      <td>A MEV bundle generator written in Rust</td>\n",
       "      <td>[Rust, Solidity]</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>meienberger / runtipi</td>\n",
       "      <td>â›ºï¸ Tipi is a homeserver for everyone! One comm...</td>\n",
       "      <td>[TypeScript, Shell, JavaScript, Other]</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hiroi-sora / Umi-OCR</td>\n",
       "      <td>OCRæ‰¹é‡å›¾ç‰‡è½¬æ–‡å­—è¯†åˆ«è½¯ä»¶ï¼Œå¸¦ç•Œé¢ï¼Œç¦»çº¿è¿è¡Œã€‚å¯æŽ’é™¤å›¾ç‰‡ä¸­æ°´å°åŒºåŸŸçš„å¹²æ‰°ï¼Œæå–å¹²å‡€çš„æ–‡æœ¬ã€‚...</td>\n",
       "      <td>[Python]</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>karpathy / nn-zero-to-hero</td>\n",
       "      <td>Neural Networks: Zero to Hero</td>\n",
       "      <td>[Jupyter, 100.0%]</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>benphelps / homepage</td>\n",
       "      <td>A highly customizable homepage (or startpage /...</td>\n",
       "      <td>[JavaScript, CSS, Dockerfile]</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>jaakkopasanen / AutoEq</td>\n",
       "      <td>Automatic headphone equalization from frequenc...</td>\n",
       "      <td>[Jupyter, 94.5%, 5.5%]</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NvChad / NvChad</td>\n",
       "      <td>An attempt to make neovim cli functional like ...</td>\n",
       "      <td>[Lua]</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mdn / content</td>\n",
       "      <td>The content behind MDN Web Docs</td>\n",
       "      <td>[Markdown]</td>\n",
       "      <td>2,610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>mantinedev / mantine</td>\n",
       "      <td>React components library with native dark them...</td>\n",
       "      <td>[TypeScript, Other]</td>\n",
       "      <td>226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>vinta / awesome-python</td>\n",
       "      <td>A curated list of awesome Python frameworks, l...</td>\n",
       "      <td>[Python, Makefile]</td>\n",
       "      <td>394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>microsoft / PowerToys</td>\n",
       "      <td>Windows system utilities to maximize productivity</td>\n",
       "      <td>[C#, C++, C, PowerShell, HTML, HLSL]</td>\n",
       "      <td>304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>apache / incubator-streampark</td>\n",
       "      <td>StreamPark, Make stream processing easier! eas...</td>\n",
       "      <td>[Java, Scala, Vue, JavaScript, Perl, Shell, Ot...</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>34306 / TrollStoreiPA</td>\n",
       "      <td>This repo saved iPA for TrollStore, work as ja...</td>\n",
       "      <td>[No, published]</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>ventoy / Ventoy</td>\n",
       "      <td>A new bootable USB solution.</td>\n",
       "      <td>[C, Shell, HTML, C++, CSS, Makefile, Other]</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ziglang / zig</td>\n",
       "      <td>General-purpose programming language and toolc...</td>\n",
       "      <td>[Zig, C++, C, JavaScript, CMake, Shell, Other]</td>\n",
       "      <td>553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>openwrt / openwrt</td>\n",
       "      <td>This repository is a mirror of https://git.ope...</td>\n",
       "      <td>[C, Makefile, Shell, Perl, Assembly, M4, Other]</td>\n",
       "      <td>879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Repository_title  \\\n",
       "0      AUTOMATIC1111 / stable-diffusion-webui   \n",
       "1           sd-webui / stable-diffusion-webui   \n",
       "2            somebasj / ParallelsDesktopCrack   \n",
       "3                  AykutSarac / jsoncrack.com   \n",
       "4                       surrealdb / surrealdb   \n",
       "5                             yt-dlp / yt-dlp   \n",
       "6                         termux / termux-app   \n",
       "7                      TheAlgorithms / Python   \n",
       "8       mtdvio / every-programmer-should-know   \n",
       "9   Alcibiades-Capital / mev_bundle_generator   \n",
       "10                      meienberger / runtipi   \n",
       "11                       hiroi-sora / Umi-OCR   \n",
       "12                 karpathy / nn-zero-to-hero   \n",
       "13                       benphelps / homepage   \n",
       "14                     jaakkopasanen / AutoEq   \n",
       "15                            NvChad / NvChad   \n",
       "16                              mdn / content   \n",
       "17                       mantinedev / mantine   \n",
       "18                     vinta / awesome-python   \n",
       "19                      microsoft / PowerToys   \n",
       "20              apache / incubator-streampark   \n",
       "21                      34306 / TrollStoreiPA   \n",
       "22                            ventoy / Ventoy   \n",
       "23                              ziglang / zig   \n",
       "24                          openwrt / openwrt   \n",
       "\n",
       "                               Repository_description  \\\n",
       "0                             Stable Diffusion web UI   \n",
       "1                             Stable Diffusion web UI   \n",
       "2                     Parallels Desktop for mac Crack   \n",
       "3   ðŸ”® Seamlessly visualize your JSON data instantl...   \n",
       "4   A scalable, distributed, collaborative, docume...   \n",
       "5   A youtube-dl fork with additional features and...   \n",
       "6   Termux - a terminal emulator application for A...   \n",
       "7                All Algorithms implemented in Python   \n",
       "8   A collection of (mostly) technical things ever...   \n",
       "9              A MEV bundle generator written in Rust   \n",
       "10  â›ºï¸ Tipi is a homeserver for everyone! One comm...   \n",
       "11  OCRæ‰¹é‡å›¾ç‰‡è½¬æ–‡å­—è¯†åˆ«è½¯ä»¶ï¼Œå¸¦ç•Œé¢ï¼Œç¦»çº¿è¿è¡Œã€‚å¯æŽ’é™¤å›¾ç‰‡ä¸­æ°´å°åŒºåŸŸçš„å¹²æ‰°ï¼Œæå–å¹²å‡€çš„æ–‡æœ¬ã€‚...   \n",
       "12                      Neural Networks: Zero to Hero   \n",
       "13  A highly customizable homepage (or startpage /...   \n",
       "14  Automatic headphone equalization from frequenc...   \n",
       "15  An attempt to make neovim cli functional like ...   \n",
       "16                    The content behind MDN Web Docs   \n",
       "17  React components library with native dark them...   \n",
       "18  A curated list of awesome Python frameworks, l...   \n",
       "19  Windows system utilities to maximize productivity   \n",
       "20  StreamPark, Make stream processing easier! eas...   \n",
       "21  This repo saved iPA for TrollStore, work as ja...   \n",
       "22                       A new bootable USB solution.   \n",
       "23  General-purpose programming language and toolc...   \n",
       "24  This repository is a mirror of https://git.ope...   \n",
       "\n",
       "                                        Language_used Contributors_count  \n",
       "0                [Python, JavaScript, Batchfile, CSS]                 22  \n",
       "1                                     [Python, Other]                 49  \n",
       "2                                             [Shell]                  2  \n",
       "3                                 [TypeScript, Other]                 13  \n",
       "4                                       [Rust, Other]                 11  \n",
       "5                                     [Python, Other]              1,013  \n",
       "6                                  [Java, C++, Other]                 61  \n",
       "7                                            [Python]                829  \n",
       "8                                            [70, 59]                  -  \n",
       "9                                    [Rust, Solidity]                  -  \n",
       "10             [TypeScript, Shell, JavaScript, Other]                 10  \n",
       "11                                           [Python]                  -  \n",
       "12                                  [Jupyter, 100.0%]                  -  \n",
       "13                      [JavaScript, CSS, Dockerfile]                 15  \n",
       "14                             [Jupyter, 94.5%, 5.5%]                 17  \n",
       "15                                              [Lua]                126  \n",
       "16                                         [Markdown]              2,610  \n",
       "17                                [TypeScript, Other]                226  \n",
       "18                                 [Python, Makefile]                394  \n",
       "19               [C#, C++, C, PowerShell, HTML, HLSL]                304  \n",
       "20  [Java, Scala, Vue, JavaScript, Perl, Shell, Ot...                 67  \n",
       "21                                    [No, published]                  1  \n",
       "22        [C, Shell, HTML, C++, CSS, Makefile, Other]                 73  \n",
       "23     [Zig, C++, C, JavaScript, CMake, Shell, Other]                553  \n",
       "24    [C, Makefile, Shell, Perl, Assembly, M4, Other]                879  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "url=\"https://github.com/\"\n",
    "driver.get(url)\n",
    "\n",
    "explore = driver.find_element(By.XPATH,'/html[1]/body[1]/div[1]/header[1]/div[1]/div[2]/div[1]/nav[1]/ul[1]/li[3]/button[1]')\n",
    "try:\n",
    "    explore.click()\n",
    "    time.sleep(5)\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(explore.get_attribute('href'))\n",
    "trending = driver.find_element(By.XPATH,'//*[@href=\"/trending\"]')\n",
    "try:\n",
    "    driver.get(trending.get_attribute('href'))\n",
    "except ElementNotInteractableException:\n",
    "    driver.get(trending.get_attribute('href'))\n",
    "    \n",
    "Repository_title= []\n",
    "Repository_description= []\n",
    "Contributors_count= []\n",
    "Language_used= []\n",
    "urls=[]\n",
    "\n",
    "try:\n",
    "    Repository_title_tag=driver.find_elements(By.XPATH,'//article[@class=\"Box-row\"]/h1/a')\n",
    "    for i in Repository_title_tag:\n",
    "        Repository_title.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Repository_title.append('-')\n",
    "try:\n",
    "    description=driver.find_elements(By.XPATH,'//article[@class=\"Box-row\"]/p')\n",
    "    for i in description:\n",
    "        Repository_description.append(i.text)\n",
    "except NoSuchElementException:\n",
    "    Repository_description.append('-')\n",
    "\n",
    "for i in [Repository_title_tag,description]:\n",
    "    for j in i:\n",
    "        if i ==Repository_title_tag:\n",
    "            Repository_title.append(j.text)\n",
    "            urls.append(j.get_attribute('href'))\n",
    "        if i==description:\n",
    "            Repository_description.append(j.text)\n",
    "    \n",
    "for url in urls:\n",
    "    driver.get(url)\n",
    "    driver.implicitly_wait(3)\n",
    "    div_list=driver.find_elements(By.XPATH,'//div[@class=\"BorderGrid BorderGrid--spacious\"]/div')\n",
    "    try:\n",
    "        Contributors_count.append(((div_list[-2].text).split())[1])\n",
    "    except:\n",
    "        Contributors_count.append('-')\n",
    "    try:\n",
    "        Language_used.append(((div_list[-1].text).split())[1::2])\n",
    "    except:\n",
    "        Language_used.append('-')\n",
    "        \n",
    "driver.close()\n",
    "github_trending=pd.DataFrame({\"Repository_title\":Repository_title[:25],\"Repository_description\":Repository_description[:25],\"Language_used\":Language_used[:25],\"Contributors_count\":Contributors_count[:25]})\n",
    "github_trending"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b790d4c7",
   "metadata": {},
   "source": [
    "**5. Scrape the details of top 100 songs on billiboard.com. Url = https:/www.billboard.com/ You have to find the following details:**\n",
    "A) Song name\n",
    "B) Artist name\n",
    "C) Last week rank\n",
    "D) Peak rank\n",
    "E) Weeks on board\n",
    "Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "04add292",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Last Week Rank</th>\n",
       "      <th>Peak Rank</th>\n",
       "      <th>Weeks On Board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As It Was</td>\n",
       "      <td>Harry Styles</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bad Habit</td>\n",
       "      <td>Steve Lacy</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>About Damn Time</td>\n",
       "      <td>Lizzo</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Running Up That Hill (A Deal With God)</td>\n",
       "      <td>Kate Bush</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sunroof</td>\n",
       "      <td>Nicky Youre &amp; dazy</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Thought You Should Know</td>\n",
       "      <td>Morgan Wallen</td>\n",
       "      <td>66</td>\n",
       "      <td>65</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2 Be Loved (Am I Ready)</td>\n",
       "      <td>Lizzo</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Wait In The Truck</td>\n",
       "      <td>HARDY Featuring Lainey Wilson</td>\n",
       "      <td>68</td>\n",
       "      <td>18</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>La Corriente</td>\n",
       "      <td>Bad Bunny &amp; Tony Dize</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Bzrp Music Sessions, Vol. 52</td>\n",
       "      <td>Bizarrap &amp; Quevedo</td>\n",
       "      <td>73</td>\n",
       "      <td>63</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Name                         Artist  \\\n",
       "0                                As It Was                   Harry Styles   \n",
       "1                                Bad Habit                     Steve Lacy   \n",
       "2                          About Damn Time                          Lizzo   \n",
       "3   Running Up That Hill (A Deal With God)                      Kate Bush   \n",
       "4                                  Sunroof             Nicky Youre & dazy   \n",
       "..                                     ...                            ...   \n",
       "95                 Thought You Should Know                  Morgan Wallen   \n",
       "96                 2 Be Loved (Am I Ready)                          Lizzo   \n",
       "97                       Wait In The Truck  HARDY Featuring Lainey Wilson   \n",
       "98                            La Corriente          Bad Bunny & Tony Dize   \n",
       "99            Bzrp Music Sessions, Vol. 52             Bizarrap & Quevedo   \n",
       "\n",
       "   Last Week Rank Peak Rank Weeks On Board  \n",
       "0               1         1             22  \n",
       "1               3         2              9  \n",
       "2               2         1             20  \n",
       "3               4         3             34  \n",
       "4               6         5             14  \n",
       "..            ...       ...            ...  \n",
       "95             66        65             11  \n",
       "96                                          \n",
       "97             68        18             17  \n",
       "98                                          \n",
       "99             73        63             22  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "url='https://www.billboard.com'\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "nav=driver.find_element(By.XPATH,\"/html/body/div[3]/header/div[1]/div/div/div[1]/button\")\n",
    "nav.click()\n",
    "time.sleep(5)\n",
    "\n",
    "hot_100=driver.find_element(By.XPATH,'/html[1]/body[1]/div[3]/div[6]/div[1]/div[1]/div[1]/ul[1]/li[1]/ul[1]/li[2]/a[1]')\n",
    "hot_100.click()\n",
    "\n",
    "Name=[]\n",
    "Artist=[]\n",
    "rank=[]\n",
    "\n",
    "Name_tag=driver.find_elements(By.XPATH,\"//h3[@class='c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 u-font-size-23@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-245 u-max-width-230@tablet-only u-letter-spacing-0028@tablet']\")\n",
    "for i in Name_tag:\n",
    "    Name.append(i.text)\n",
    "Artist_tag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only u-font-size-20@tablet']\")\n",
    "for i in Artist_tag:\n",
    "    Artist.append(i.text)\n",
    "rankTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max lrv-u-padding-tb-050@mobile-max u-font-size-32@tablet']\")\n",
    "for i in rankTag[:3]:\n",
    "    rank.append(i.text )\n",
    "Rank=[]\n",
    "nameTag=driver.find_elements(By.XPATH,\"//h3[@class='c-title  a-no-trucate a-font-primary-bold-s u-letter-spacing-0021 lrv-u-font-size-18@tablet lrv-u-font-size-16 u-line-height-125 u-line-height-normal@mobile-max a-truncate-ellipsis u-max-width-330 u-max-width-230@tablet-only']\")\n",
    "for i in nameTag:\n",
    "    Name.append(i.text )\n",
    "artistTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only']\")\n",
    "for i in artistTag:\n",
    "    Artist.append(i.text )\n",
    "    \n",
    "RankTag=driver.find_elements(By.XPATH,\"//span[@class='c-label  a-font-primary-m lrv-u-padding-tb-050@mobile-max']\")\n",
    "for i in RankTag:\n",
    "    Rank.append(i.text)\n",
    "for i in Rank:\n",
    "    if i=='':\n",
    "        Rank.remove(i)\n",
    "last_week_rank=Rank[0::3]\n",
    "last_week_rank.insert(0,rank[0])\n",
    "peak_rank=Rank[1::3]\n",
    "peak_rank.insert(0,rank[1])\n",
    "weeks_on_board=Rank[2::3]\n",
    "weeks_on_board.insert(0,rank[2])\n",
    "\n",
    "driver.close()\n",
    "songs_top=pd.DataFrame({\"Name\":Name[:100],\"Artist\":Artist[:100],\"Last Week Rank\":last_week_rank[0:100],\"Peak Rank\":peak_rank[0:100],\"Weeks On Board\":weeks_on_board[0:100]})\n",
    "songs_top"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b80faf",
   "metadata": {},
   "source": [
    "**6. Scrape the details of Highest selling novels.**\n",
    "A) Book name\n",
    "B) Author name\n",
    "C) Volumes sold\n",
    "D) Publisher\n",
    "E) Genre\n",
    "Url - https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "866bdb77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book Name</th>\n",
       "      <th>Author Name</th>\n",
       "      <th>Volumes sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>Crime, Thriller &amp; Adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>Children's Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>Romance &amp; Sagas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>General &amp; Literary Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>Young Adult Fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>Biography: General</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>Food &amp; Drink: General</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book Name       Author Name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes sold        Publisher                        Genre  \n",
       "0     5,094,805       Transworld  Crime, Thriller & Adventure  \n",
       "1     4,475,152       Bloomsbury           Children's Fiction  \n",
       "2     4,200,654       Bloomsbury           Children's Fiction  \n",
       "3     4,179,479       Bloomsbury           Children's Fiction  \n",
       "4     3,758,936     Random House              Romance & Sagas  \n",
       "..          ...              ...                          ...  \n",
       "95      807,311     Random House   General & Literary Fiction  \n",
       "96      794,201          Penguin        Food & Drink: General  \n",
       "97      792,187  Scholastic Ltd.          Young Adult Fiction  \n",
       "98      791,507            Orion           Biography: General  \n",
       "99      791,095          Penguin        Food & Drink: General  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "url='https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare'\n",
    "driver.get(url)\n",
    "\n",
    "book_name=[]\n",
    "author_name=[]\n",
    "volumes_sold=[]\n",
    "publisher=[]\n",
    "genre=[]\n",
    "\n",
    "b_name=driver.find_elements(By.XPATH,'/html[1]/body[1]/div[1]/div[2]/div[2]/div[1]/div[2]/div[1]/table[1]/tbody[1]/tr/td[2]')\n",
    "try:\n",
    "    for i in b_name:\n",
    "        book_name.append(i.text)\n",
    "except:\n",
    "    book_name.append(\"-\")\n",
    "    \n",
    "a_name=driver.find_elements(By.XPATH,'/html[1]/body[1]/div[1]/div[2]/div[2]/div[1]/div[2]/div[1]/table[1]/tbody[1]/tr/td[3]')\n",
    "try:\n",
    "    for i in a_name:\n",
    "        author_name.append(i.text)\n",
    "except:\n",
    "    author_name.append(\"-\")\n",
    "    \n",
    "v_sold=driver.find_elements(By.XPATH,'/html[1]/body[1]/div[1]/div[2]/div[2]/div[1]/div[2]/div[1]/table[1]/tbody[1]/tr/td[4]')\n",
    "try:\n",
    "    for i in v_sold:\n",
    "        volumes_sold.append(i.text)\n",
    "except:\n",
    "    volumes_sold.append(\"-\")\n",
    "    \n",
    "b_publisher=driver.find_elements(By.XPATH,'/html[1]/body[1]/div[1]/div[2]/div[2]/div[1]/div[2]/div[1]/table[1]/tbody[1]/tr/td[5]')\n",
    "try:\n",
    "    for i in b_publisher:\n",
    "        publisher.append(i.text)\n",
    "except:\n",
    "    publisher.append(\"-\")\n",
    "    \n",
    "b_genre=driver.find_elements(By.XPATH,'/html[1]/body[1]/div[1]/div[2]/div[2]/div[1]/div[2]/div[1]/table[1]/tbody[1]/tr/td[6]')\n",
    "try:\n",
    "    for i in b_genre:\n",
    "        genre.append(i.text)\n",
    "except:\n",
    "    genre.append(\"-\")\n",
    "    \n",
    "driver.close()\n",
    "Highest_selling_novels=pd.DataFrame({'Book Name':book_name,'Author Name':author_name,'Volumes sold':volumes_sold,'Publisher':publisher,'Genre':genre})\n",
    "Highest_selling_novels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5190065",
   "metadata": {},
   "source": [
    "**7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "Url = https://www.imdb.com/list/ls095964455/ You have to find the following details:**\n",
    "A) Name\n",
    "B) Year span\n",
    "C) Genre\n",
    "D) Run time\n",
    "E) Ratings\n",
    "F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "f2268b92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Run Time</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011â€“2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>9.2</td>\n",
       "      <td>2,046,719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016â€“ )</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>8.7</td>\n",
       "      <td>1,143,245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010â€“2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>967,525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017â€“2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>7.5</td>\n",
       "      <td>288,651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014â€“2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>7.6</td>\n",
       "      <td>248,237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013â€“2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>7.4</td>\n",
       "      <td>49,528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017â€“2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>7.8</td>\n",
       "      <td>60,530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005â€“2020)</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>8.1</td>\n",
       "      <td>194,678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015â€“2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>7.1</td>\n",
       "      <td>41,004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>8.6</td>\n",
       "      <td>236,164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011â€“2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things     (2016â€“ )    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010â€“2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017â€“2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014â€“2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013â€“2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017â€“2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds  (2005â€“2020)     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015â€“2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "   Run Time Ratings      Votes  \n",
       "0    57 min     9.2  2,046,719  \n",
       "1    51 min     8.7  1,143,245  \n",
       "2    44 min     8.1    967,525  \n",
       "3    60 min     7.5    288,651  \n",
       "4    43 min     7.6    248,237  \n",
       "..      ...     ...        ...  \n",
       "95   42 min     7.4     49,528  \n",
       "96   50 min     7.8     60,530  \n",
       "97   42 min     8.1    194,678  \n",
       "98   45 min     7.1     41,004  \n",
       "99  572 min     8.6    236,164  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "url='https://www.imdb.com/list/ls095964455'\n",
    "driver.get(url)\n",
    "\n",
    "name=[]\n",
    "year=[]\n",
    "genre=[]\n",
    "run_time=[]\n",
    "ratings=[]\n",
    "votes=[]\n",
    "\n",
    "s_name=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/a')\n",
    "try:\n",
    "    for i in s_name:\n",
    "        name.append(i.text)\n",
    "except:\n",
    "    name.append(\"--\") \n",
    "    \n",
    "s_year=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/span[2]')\n",
    "try:\n",
    "    for i in s_year:\n",
    "        year.append(i.text)\n",
    "except:\n",
    "    year.append(\"--\")   \n",
    "\n",
    "s_genre=driver.find_elements(By.XPATH,'//p[@class=\"text-muted text-small\"]/span[5]')\n",
    "try:\n",
    "    for i in s_genre:\n",
    "        genre.append(i.text)\n",
    "except:\n",
    "    genre.append(\"--\")\n",
    "    \n",
    "r_time=driver.find_elements(By.XPATH,'//p[@class=\"text-muted text-small\"]/span[3]')\n",
    "try:\n",
    "    for i in r_time:\n",
    "        run_time.append(i.text)\n",
    "except:\n",
    "    run_time.append(\"--\")   \n",
    "\n",
    "rating=driver.find_elements(By.XPATH,'//div[@class=\"ipl-rating-widget\"]/div/span[2]')\n",
    "try:\n",
    "    for i in rating:\n",
    "        ratings.append(i.text)\n",
    "except:\n",
    "    ratings.append(\"--\")\n",
    "    \n",
    "vote=driver.find_elements(By.XPATH,'//span[@name=\"nv\"]')\n",
    "try:\n",
    "    for i in vote:\n",
    "        votes.append(i.text)\n",
    "except:\n",
    "    votes.append(\"--\")\n",
    "    \n",
    "driver.close()\n",
    "tv_series=pd.DataFrame({'Name':name,'Year Span':year,'Genre':genre,'Run Time':run_time,'Ratings':ratings,'Votes':votes})\n",
    "tv_series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d243851",
   "metadata": {},
   "source": [
    "**8. Details of Datasets from UCI machine learning repositories.\n",
    "Url = https://archive.ics.uci.edu/ You have to find the following details:**\n",
    "A) Dataset name\n",
    "B) Data type\n",
    "C) Task\n",
    "D) Attribute type\n",
    "E) No of instances\n",
    "F) No of attribute G) Year\n",
    "Note: - from the home page you have to go to the Show All Dataset page through code.\n",
    "ASSIGNMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "785e2ffa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset name</th>\n",
       "      <th>Data type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute type</th>\n",
       "      <th>Instances</th>\n",
       "      <th>Attribute</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Abalone</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>4177</td>\n",
       "      <td>8</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Adult</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Annealing</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>798</td>\n",
       "      <td>38</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Anonymous Microsoft Web Data</td>\n",
       "      <td></td>\n",
       "      <td>Recommender-Systems</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>37711</td>\n",
       "      <td>294</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arrhythmia</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>452</td>\n",
       "      <td>279</td>\n",
       "      <td>1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>Influenza outbreak event prediction via Twitte...</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>75840</td>\n",
       "      <td>525</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>618</th>\n",
       "      <td>Turkish Music Emotion Dataset</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>400</td>\n",
       "      <td>50</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>Maternal Health Risk Data Set</td>\n",
       "      <td></td>\n",
       "      <td>Classification</td>\n",
       "      <td></td>\n",
       "      <td>1014</td>\n",
       "      <td>7</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>Room Occupancy Estimation</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>10129</td>\n",
       "      <td>16</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>Image Recognition Task Execution Times in Mobi...</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4000</td>\n",
       "      <td>2</td>\n",
       "      <td>2021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>622 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Dataset name  \\\n",
       "0                                              Abalone   \n",
       "1                                                Adult   \n",
       "2                                            Annealing   \n",
       "3                         Anonymous Microsoft Web Data   \n",
       "4                                           Arrhythmia   \n",
       "..                                                 ...   \n",
       "617  Influenza outbreak event prediction via Twitte...   \n",
       "618                      Turkish Music Emotion Dataset   \n",
       "619                      Maternal Health Risk Data Set   \n",
       "620                          Room Occupancy Estimation   \n",
       "621  Image Recognition Task Execution Times in Mobi...   \n",
       "\n",
       "                      Data type                  Task  \\\n",
       "0                 Multivariate        Classification    \n",
       "1                 Multivariate        Classification    \n",
       "2                 Multivariate        Classification    \n",
       "3                                Recommender-Systems    \n",
       "4                 Multivariate        Classification    \n",
       "..                          ...                   ...   \n",
       "617               Multivariate        Classification    \n",
       "618               Multivariate        Classification    \n",
       "619                                   Classification    \n",
       "620  Multivariate, Time-Series        Classification    \n",
       "621                 Univariate            Regression    \n",
       "\n",
       "                  Attribute type Instances Attribute   Year  \n",
       "0    Categorical, Integer, Real      4177         8   1995   \n",
       "1          Categorical, Integer     48842        14   1996   \n",
       "2    Categorical, Integer, Real       798        38          \n",
       "3                   Categorical     37711       294   1998   \n",
       "4    Categorical, Integer, Real       452       279   1998   \n",
       "..                           ...       ...       ...    ...  \n",
       "617               Integer, Real     75840       525   2020   \n",
       "618               Integer, Real       400        50   2020   \n",
       "619                                  1014         7   2020   \n",
       "620                        Real     10129        16   2021   \n",
       "621                        Real      4000         2   2021   \n",
       "\n",
       "[622 rows x 7 columns]"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver=webdriver.Chrome()\n",
    "driver.maximize_window()\n",
    "url='https://archive.ics.uci.edu/ml/index.php'\n",
    "driver.get(url)\n",
    "Dataset= driver.find_elements(By.XPATH,\"//span[@class='normal']/b/a\")[0].get_attribute('href')\n",
    "driver.get(Dataset)\n",
    "data=[]\n",
    "try:\n",
    "    data_tag=driver.find_elements(By.XPATH,\"//td//p[@class='normal']\")\n",
    "    for i in data_tag[8:4362]:\n",
    "        data.append(i.text )\n",
    "except:\n",
    "    data.append('-')\n",
    "Dataset_name=data[::7]\n",
    "Data_type=data[1::7]\n",
    "Task=data[2::7]\n",
    "Attribute_type=data[3::7]\n",
    "instances=data[4::7]\n",
    "attribute=data[5::7]\n",
    "Year=data[6::7]\n",
    "\n",
    "driver.close()\n",
    "Datasets= pd.DataFrame({\"Dataset name\":Dataset_name,\"Data type\":Data_type,\"Task\":Task,\"Attribute type\":Attribute_type,\"Instances\":instances,\"Attribute\":attribute,\"Year\":Year})\n",
    "Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af585684",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
